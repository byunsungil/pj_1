import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import os
import plotly.express as px
import numpy as np
import seaborn as sns
import requests
from bs4 import BeautifulSoup
from collections import Counter
import re
from datetime import datetime, timedelta
import matplotlib.font_manager as fm
import pymysql
from wordcloud import WordCloud
from sqlalchemy import create_engine

# í•œê¸€ í°íŠ¸ ì„¤ì •
matplotlib.rcParams['font.family'] = 'Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] = False

# Streamlit ì•± êµ¬ì„±
st.set_page_config(page_title="ë²•ì¸ì°¨ëŸ‰ ëŒ€ì‹œë³´ë“œ", layout="wide")
menu = st.sidebar.radio("ðŸ“‹ ë©”ë‰´ ì„ íƒ", ["ì°¨ëŸ‰ ë“±ë¡ í˜„í™©","ì°¨ëŸ‰ ì •ë³´ í•„í„°", "ë‰´ìŠ¤ ì •ë³´", "íŠ¸ìœ„í„° ë°˜ì‘", "ìœ íŠœë¸Œ ë°˜ì‘" ,"ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸"])       

###############################################################################################################

import pandas as pd
import streamlit as st
from sqlalchemy import create_engine

if menu == "ì°¨ëŸ‰ ë“±ë¡ í˜„í™©":
    st.title("ðŸš— ìˆ˜ìž… ë²•ì¸ì°¨ëŸ‰ ë“±ë¡ í†µê³„ (ì°¨ì¢…ë³„)")

    # âœ… MySQLì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
    @st.cache_data
    def load_car_data_from_mysql():
        db_user = "runnnn"
        db_password = "1111"
        db_host = "localhost"
        db_port = "3306"
        db_name = "car_reg"
        table_name = "car_reg"

        engine = create_engine(f"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}")
        query = f"SELECT * FROM {table_name}"
        car_reg_df = pd.read_sql(query, con=engine)

        # ì „ì²˜ë¦¬
        car_reg_df = car_reg_df.set_index("ì°¨ì¢…ë³„").T
        car_reg_df.index.name = "ì›”"
        car_reg_df.index = pd.to_datetime(car_reg_df.index, format="%y%m")
        return car_reg_df

    # âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    car_reg_df = load_car_data_from_mysql()

    # âœ… ì°¨ì¢… ì„ íƒ
    selected_models = st.multiselect("ðŸš˜ ì°¨ì¢… ì„ íƒ", car_reg_df.columns.tolist())

    if selected_models:
        car_reg_df_selected = car_reg_df[selected_models]

        # âœ… ë“±ë¡ ìˆ˜ ê¸°ì¤€ ë¶„ë¥˜
        high_volume = [model for model in selected_models if car_reg_df_selected[model].max() >= 5000]
        low_volume = [model for model in selected_models if car_reg_df_selected[model].max() < 5000]

        st.subheader("ðŸ“ˆ ë“±ë¡ëŒ€ìˆ˜ 5,000ëŒ€ ì´ìƒ ëª¨ë¸")
        if high_volume:
            st.line_chart(car_reg_df_selected[high_volume])
        else:
            st.info("5,000ëŒ€ ì´ìƒ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.subheader("ðŸ“‰ ë“±ë¡ëŒ€ìˆ˜ 5,000ëŒ€ ë¯¸ë§Œ ëª¨ë¸")
        if low_volume:
            st.line_chart(car_reg_df_selected[low_volume])
        else:
            st.info("5,000ëŒ€ ë¯¸ë§Œ ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        # âœ… ì „ì²´ ì°¨íŠ¸ (ì¤‘ë³µë˜ì„œ ì£¼ì„ì²˜ë¦¬)
        # st.line_chart(car_reg_df_selected)

        # âœ… ìµœê·¼ 12ê°œì›” í‰ê·  ë¹„êµ
        car_reg_df_recent = car_reg_df_selected[-24:].copy()
        car_reg_df_2023 = car_reg_df_recent[car_reg_df_recent.index.year == 2023].mean()
        car_reg_df_2024 = car_reg_df_recent[car_reg_df_recent.index.year == 2024].mean()

        st.write("ðŸ“Š í‰ê·  ë“±ë¡ ìˆ˜ (ìµœê·¼ 12ê°œì›”)")
        for model in selected_models:
            col1, col2, col3 = st.columns(3)
            col1.metric(f"ðŸš˜ {model} - 2023 í‰ê· ", f"{car_reg_df_2023[model]:.0f}ëŒ€")
            col2.metric(f"ðŸš˜ {model} - 2024 í‰ê· ", f"{car_reg_df_2024[model]:.0f}ëŒ€")
            diff = car_reg_df_2024[model] - car_reg_df_2023[model]
            rate = (diff / car_reg_df_2023[model]) * 100 if car_reg_df_2023[model] != 0 else 0
            col3.metric("ðŸ“ˆ ì „ë…„ ëŒ€ë¹„ ë³€í™”", f"{diff:+.0f}ëŒ€", f"{rate:+.1f}%")
    else:
        st.info("ë¹„êµí•  ì°¨ì¢…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")


###############################################################################################################
    
elif menu == "ì°¨ëŸ‰ ì •ë³´ í•„í„°":
    st.title("ðŸš˜ ìˆ˜ìž…ì°¨ íŒë§¤ ë°ì´í„° ë¹„êµ (ì—°ë„ë³„/ì›”ë³„ ì‹œê°í™”)")

    @st.cache_data
    def load_data():
        conn = pymysql.connect(
            host="localhost",
            user="runnnn",
            password="1111",
            database="car_sales",
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        with conn.cursor() as cursor:
            cursor.execute("SELECT * FROM carsales")
            result = cursor.fetchall()
        conn.close()

        df = pd.DataFrame(result)
        df = df.drop_duplicates(subset=["ìžë™ì°¨ ëª¨ë¸", "ë…„ë„", "ì›”"])
        return df

    # âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = load_data()

    # âœ… í•„í„° ì˜ì—­
    available_years = sorted(df["ë…„ë„"].unique())
    selected_years = st.multiselect("ðŸ“† ì—°ë„ ì„ íƒ", available_years, default=available_years)

    car_models = df['ìžë™ì°¨ ëª¨ë¸'].unique()
    selected_models = st.multiselect("ðŸš˜ ëª¨ë¸ ì„ íƒ", car_models)

    excluded = ['ë…„ë„', 'ì›”', 'ìžë™ì°¨ ëª¨ë¸']
    candidate_metrics = [col for col in df.columns if col not in excluded]
    selected_metrics = st.multiselect("ðŸ“Š ë¹„êµ í•­ëª© ì„ íƒ", candidate_metrics)

    # âœ… ì¡°ê±´ ì¶©ì¡± ì‹œ í•„í„°ë§ ë° ì‹œê°í™”
    if selected_models and selected_metrics and selected_years:
        filtered_df = df[
            (df['ìžë™ì°¨ ëª¨ë¸'].isin(selected_models)) &
            (df['ë…„ë„'].isin(selected_years))
        ].copy()

        if 'ì „ì›”ëŒ€ë¹„_ì¦ê°' in filtered_df.columns:
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'].astype(str)
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'].str.extract(r'([+-]?\d+)')[0]
            filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'] = pd.to_numeric(filtered_df['ì „ì›”ëŒ€ë¹„_ì¦ê°'], errors='coerce')

        for metric in selected_metrics:
            fig = px.line(
                filtered_df,
                x="ì›”",
                y=metric,
                color="ìžë™ì°¨ ëª¨ë¸",
                line_dash="ë…„ë„",
                markers=True,
                title=f"{metric} ì›”ë³„ ì¶”ì´ (ì—°ë„ë³„ ë¼ì¸ êµ¬ë¶„)",
            )

            if metric == "ì „ì›”ëŒ€ë¹„_ì¦ê°":
                fig.update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='gray')
                fig.update_layout(yaxis_range=[
                    filtered_df[metric].min() - 10,
                    filtered_df[metric].max() + 10
                ])

            fig.update_layout(
                xaxis=dict(tickmode='linear', tick0=1, dtick=1),
                legend_title_text="ìžë™ì°¨ ëª¨ë¸",
                legend=dict(orientation="h", yanchor="bottom", y=-0.3, xanchor="center", x=0.5)
            )
            st.plotly_chart(fig)
    else:
        st.info("ì—°ë„, ëª¨ë¸, ë¹„êµ í•­ëª©ì„ ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”.")


###############################################################################################################

elif menu == "ë‰´ìŠ¤ ì •ë³´":
    st.title("ðŸ“° ë²•ì¸ ê´€ë ¨ ë‰´ìŠ¤")
    st.info("ì´ ì„¹ì…˜ì€ ë‰´ìŠ¤ í¬ë¡¤ë§ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ë¥¸ ê¸°ëŠ¥ì€ ê¸°ì¡´ê³¼ ë™ì¼í•©ë‹ˆë‹¤.")

    QUERY = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ìž…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ì°¨ ì œë„")
    FILE_PATH = f"news_data/{QUERY}_news.csv"
    os.makedirs("news_data", exist_ok=True)

    def parse_date(text):
        if 'ì¼ ì „' in text:
            return datetime.now() - timedelta(days=int(text.replace('ì¼ ì „', '').strip()))
        elif 'ì‹œê°„ ì „' in text:
            return datetime.now()
        elif '.' in text:
            try:
                return datetime.strptime(text.strip(), "%Y.%m.%d.")
            except:
                return None
        return None

    def crawl_news(query, pages=1): # sql ì—°ë™ ,ê²€ìƒ‰ì–´ news ìžë™ ì €ìž¥
        data = []
        for page in range(1, pages + 1):
            start = (page - 1) * 10 + 1
            url = f'https://search.naver.com/search.naver?where=news&query={query}&start={start}'
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                title_tag = article.select_one('a.news_tit')
                if not title_tag:
                    continue
                title = title_tag['title']
                link = title_tag['href']
                press_tag = article.select_one('a.info.press')
                press = press_tag.text.strip() if press_tag else 'Unknown'
                date_tag = article.select('span.info')[-1]
                raw_date = date_tag.text.strip() if date_tag else ''
                parsed = parse_date(raw_date)
                date = parsed.strftime('%Y-%m-%d') if parsed else datetime.today().strftime('%Y-%m-%d')
                summary_tag = article.select_one('div.dsc_wrap')
                summary = summary_tag.text.strip() if summary_tag else ''
                data.append({'title': title, 'press': press, 'date': date, 'summary': summary, 'url': link})
        return pd.DataFrame(data)

    def save_news(df_new, query):
        # 1ï¸âƒ£ ê¸°ì¡´ CSV ë³‘í•©
        file_path = f"news_data/{query}_news.csv"
        if os.path.exists(file_path):
            df_old = pd.read_csv(file_path)
            df_all = pd.concat([df_old, df_new]).drop_duplicates(subset=['url'])
        else:
            df_all = df_new
    
        # 2ï¸âƒ£ ê²€ìƒ‰ì–´ ì»¬ëŸ¼ ì¶”ê°€
        df_all["query"] = query
    
        # 3ï¸âƒ£ CSV ì €ìž¥
        df_all.to_csv(file_path, index=False, encoding='utf-8-sig')
    
        # 4ï¸âƒ£ MySQL ì €ìž¥ (ì¤‘ë³µ ê°€ëŠ¥ì„± ìžˆìŒ â†’ url ê¸°ì¤€ìœ¼ë¡œ ì •ë¦¬ ì¶”ì²œ)
        try:
            engine = create_engine("mysql+pymysql://runnnn:1111@localhost:3306/news_db")
            df_new["query"] = query  # âœ… ìƒˆë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì—ë„ ê²€ìƒ‰ì–´ ì¶”ê°€
            df_new.to_sql(name="news_data", con=engine, if_exists="append", index=False)
        except Exception as e:
            st.error(f"MySQL ì €ìž¥ ì‹¤íŒ¨: {e}")
    
        return df_all

    def show_news_paginated(df):
        st.subheader("ðŸ“° ë‰´ìŠ¤ ì œëª© ë° ìš”ì•½ ë³´ê¸° (íŽ˜ì´ì§€ë³„)")
        def truncate(text, limit=100):
            return text if len(text) <= limit else text[:limit] + "..."

        page_size = 10
        total_pages = (len(df) - 1) // page_size + 1
        page = st.number_input("íŽ˜ì´ì§€ ì„ íƒ", min_value=1, max_value=total_pages, step=1)
        start = (page - 1) * page_size
        end = start + page_size

        for i, row in df.iloc[start:end].iterrows():
            st.markdown(f"### ðŸ”— [{row['title']}]({row['url']})")
            st.write(f"ðŸ“ ìš”ì•½: {truncate(row['summary'], 100)}")
            st.markdown("---")

    pages = st.number_input("í¬ë¡¤ë§í•  ë‰´ìŠ¤ íŽ˜ì´ì§€ ìˆ˜ ìž…ë ¥ (10ê°œ ë‹¨ìœ„)", min_value=1, max_value=10, step=1)

    if st.button("ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§í•˜ê¸°"):
        df_today = crawl_news(QUERY, pages)
        df_all = save_news(df_today, QUERY)  # âœ… ë‘ ë²ˆì§¸ ì¸ìž ì¶”ê°€
        st.success(f"{len(df_today)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ! ì „ì²´ {len(df_all)}ê±´ ì €ìž¥ë¨.")

    elif os.path.exists(FILE_PATH):
        df_all = pd.read_csv(FILE_PATH)
    else:
        st.warning("ì €ìž¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        df_all = pd.DataFrame()

    if not df_all.empty:
        st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_all[['date', 'title', 'press', 'summary']])

        show_news_paginated(df_all)
    else:
        st.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
###############################################################################################################

elif menu == "íŠ¸ìœ„í„° ë°˜ì‘":
    st.title("ðŸš— íŠ¸ìœ„í„° ë°˜ì‘ ìˆ˜ì§‘ ê²°ê³¼ ë³´ê¸°")

    # âœ… MySQLì—ì„œ íŠ¸ìœ„í„° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    @st.cache_data
    def load_data_tw():
        db_user = "runnnn"
        db_password = "1111"
        db_host = "localhost"
        db_port = "3306"
        db_name = "tweet_contents"
        table_name = "tweet_contents"

        engine = create_engine(f"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}")
        query = f"SELECT url, text FROM {table_name}"
        df = pd.read_sql(query, con=engine)
        return df

    df_tw = load_data_tw()

    if df_tw.empty:
        st.error("âŒ MySQLì—ì„œ íŠ¸ìœ„í„° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.success("âœ… íŠ¸ìœ„í„° ë°ì´í„° ë¡œë”© ì™„ë£Œ!")

        search_keyword = st.text_input("ðŸ” í‚¤ì›Œë“œë¡œ ë‚´ìš© ê²€ìƒ‰ (ì˜ˆ: ë²•ì¸, ì—°ë‘ìƒ‰)")

        if search_keyword:
            filtered = df_tw[df_tw["text"].str.contains(search_keyword, case=False, na=False)]

            if not filtered.empty:
                for _, row in filtered.iterrows():
                    st.markdown("**ðŸ“ íŠ¸ìœ— ë‚´ìš©**")
                    st.write(row["text"])
                    st.markdown("---")
            else:
                st.warning("â— ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
                
##############################################################################################################

elif menu == "ìœ íŠœë¸Œ ë°˜ì‘":
    st.title("ðŸŸ¢ ì—°ë‘ìƒ‰ ë²ˆí˜¸íŒ ê´€ë ¨ ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„")

    # âœ… MySQLì—ì„œ ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶ˆëŸ¬ì˜¤ê¸° (ì»¬ëŸ¼ëª…ì´ '0'ì¸ ê²½ìš° ì²˜ë¦¬)
    @st.cache_data
    def load_data_youtube():
        db_user = "runnnn"
        db_password = "1111"
        db_host = "localhost"
        db_port = "3306"
        db_name = "youtube"
        table_name = "youtube"

        # SQLAlchemy ì—°ê²°
        engine = create_engine(f"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}")

        # âœ… ì»¬ëŸ¼ëª…ì´ ìˆ«ìžì´ë¯€ë¡œ ì—­ë”°ì˜´í‘œë¡œ ê°ì‹¸ê³ , ASë¡œ ì´ë¦„ ë³€ê²½
        query = f"SELECT `0` AS comment FROM {table_name}"
        df = pd.read_sql(query, con=engine)
        return df

    # âœ… ëŒ“ê¸€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df_youtube = load_data_youtube()
    comments = df_youtube["comment"].dropna().astype(str)

    # âœ… ì´ ëŒ“ê¸€ ìˆ˜ í‘œì‹œ
    st.write(f"ì´ ëŒ“ê¸€ ìˆ˜: {len(comments)}ê°œ")

    # ðŸ” í‚¤ì›Œë“œ ê²€ìƒ‰
    search_keyword = st.text_input("ëŒ“ê¸€ ë‚´ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    if search_keyword:
        filtered = comments[comments.str.contains(search_keyword, case=False)]
        st.write(f"ðŸ” '{search_keyword}'ê°€ í¬í•¨ëœ ëŒ“ê¸€ ìˆ˜: {len(filtered)}ê°œ")
        st.dataframe(filtered)

    # ðŸ“Š ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    st.subheader("ðŸ“Š ì£¼ìš” í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")

    all_text = " ".join(comments.tolist())

    # âœ… í°íŠ¸ ê²½ë¡œ ì§€ì • (ìœˆë„ìš° í•œê¸€ í°íŠ¸)
    font_path = r"C:\Users\erety\sk_13_5_1st_sungil\1st_pj_g5\ìƒˆ í´ë”\NanumGothicCoding.ttf"

    wc = WordCloud(
        font_path=font_path,
        width=800,
        height=400,
        background_color="white"
    ).generate(all_text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    st.pyplot(plt)



###############################################################################################################

elif menu == "ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸":
    st.title("â“ ìžì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)")

    # MySQLì—ì„œ FAQ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    def load_data_from_mysql(host, user, password, database, table_name="faq"):
        conn = pymysql.connect(
            host=host,
            user=user,
            password=password,
            db=database,
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        with conn.cursor() as cursor:
            cursor.execute(f"SELECT question, answer FROM {table_name}")
            result = cursor.fetchall()
        conn.close()
        return pd.DataFrame(result)

    # Streamlit FAQ íŽ˜ì´ì§€ ì‹¤í–‰ í•¨ìˆ˜
    def render_faq():
        st.write("ì•„ëž˜ ì§ˆë¬¸ì„ í´ë¦­í•˜ë©´ ë‹µë³€ì„ í™•ì¸í•  ìˆ˜ ìžˆì–´ìš”.")
    
        host = "127.0.0.1"
        user = "runnnn"
        password = "1111"
        database = "FAQ"
        table_name = "faq"
    
        try:
            df = load_data_from_mysql(host, user, password, database, table_name)
        except Exception as e:
            st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return
    
        query = st.text_input("ðŸ” ì§ˆë¬¸ ê²€ìƒ‰", "")
        if query:
            df = df[df["question"].str.contains(query, case=False, na=False)]
    
        if df.empty:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
    
        for idx, row in enumerate(df.itertuples(index=False), start=1):
            question = str(row.question).strip()
            
            # âœ… ìˆ«ìž ì•žì— ì´ëª¨ì§€ ì¶”ê°€ë¡œ ê°•ì¡° + êµµê²Œ ì²˜ë¦¬
            expander_title = f"ðŸ”¸ **{idx}. {question}**"
            
            with st.expander(expander_title):
                st.write(row.answer)


    # âœ… ì—¬ê¸°ê°€ í•µì‹¬! ë©”ë‰´ì— ì§„ìž…í–ˆì„ ë•Œ ë°”ë¡œ ì‹¤í–‰
    render_faq()

