# ë‰´ìŠ¤ ì •ë³´, ê²€ìƒ‰ì–´ ì…ë ¥, ìš”ì•½, ë§í¬
# í˜ì´ì§€ ì„ íƒë¶€ë¶„ ìˆ˜ì • í•„ìš”ìš”

elif menu == "ë‰´ìŠ¤ ì •ë³´":
    st.title("ğŸ“° ë²•ì¸ ê´€ë ¨ ë‰´ìŠ¤")
    QUERY = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ì°¨ ì œë„")
    FILE_PATH = f"news_data/{QUERY}_news.csv"
    os.makedirs("news_data", exist_ok=True)

    def parse_date(text):
        if 'ì¼ ì „' in text:
            return datetime.now() - timedelta(days=int(text.replace('ì¼ ì „', '').strip()))
        elif 'ì‹œê°„ ì „' in text:
            return datetime.now()
        elif '.' in text:
            try:
                return datetime.strptime(text.strip(), "%Y.%m.%d.")
            except:
                return None
        return None

    def crawl_news(query, pages=1):
        data = []
        for page in range(1, pages + 1):
            start = (page - 1) * 10 + 1
            url = f'https://search.naver.com/search.naver?where=news&query={query}&start={start}'
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                title_tag = article.select_one('a.news_tit')
                if not title_tag:
                    continue
                title = title_tag['title']
                link = title_tag['href']
                press_tag = article.select_one('a.info.press')
                press = press_tag.text.strip() if press_tag else 'Unknown'
                date_tag = article.select('span.info')[-1]
                raw_date = date_tag.text.strip() if date_tag else ''
                parsed = parse_date(raw_date)
                date = parsed.strftime('%Y-%m-%d') if parsed else datetime.today().strftime('%Y-%m-%d')
                summary_tag = article.select_one('div.dsc_wrap')
                summary = summary_tag.text.strip() if summary_tag else ''
                data.append({'title': title, 'press': press, 'date': date, 'summary': summary, 'url': link})
        return pd.DataFrame(data)

    def save_news(df_new):
        if os.path.exists(FILE_PATH):
            df_old = pd.read_csv(FILE_PATH)
            df_all = pd.concat([df_old, df_new]).drop_duplicates(subset=['url'])
        else:
            df_all = df_new
        df_all.to_csv(FILE_PATH, index=False, encoding='utf-8-sig')
        return df_all

    # ë‰´ìŠ¤ ì¶œë ¥ ë° í˜ì´ì§€ ì„ íƒ í•¨ìˆ˜
    def show_news(df):
        st.subheader("ğŸ“° ë‰´ìŠ¤ ì œëª© ë° ìš”ì•½ ë³´ê¸°")
        num_per_page = 10
        total_items = len(df)
        total_pages = (total_items - 1) // num_per_page + 1

        # ì„¸ì…˜ ìƒíƒœì— í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ ì €ì¥ (ì´ˆê¸°ê°’ 1)
        if 'current_page' not in st.session_state:
            st.session_state.current_page = 1

        # í‘œì‹œí•  ë‰´ìŠ¤ ë°ì´í„° ìŠ¬ë¼ì´ì‹±
        start_idx = (st.session_state.current_page - 1) * num_per_page
        end_idx = start_idx + num_per_page
        df_page = df.iloc[start_idx:end_idx]

        def truncate(text, limit=100):
            return text if len(text) <= limit else text[:limit] + "..."
        
        # ë‰´ìŠ¤ í•­ëª© ì¶œë ¥
        for i, row in df_page.iterrows():
            st.markdown(f"### ğŸ”— [{row['title']}]({row['url']})")
            st.write(f"ğŸ“ ìš”ì•½: {truncate(row['summary'], 100)}")
            st.markdown("---")
        
        # í•˜ë‹¨ì— ê¹”ë”í•œ ë¼ë””ì˜¤ ë²„íŠ¼ìœ¼ë¡œ í˜ì´ì§€ ë²ˆí˜¸ ì„ íƒ (ê°€ë¡œ ì •ë ¬)
        selected_page = st.radio("í˜ì´ì§€ ì„ íƒ", list(range(1, total_pages + 1)),
                                 index=st.session_state.current_page - 1,
                                 horizontal=True)
        st.session_state.current_page = selected_page

    pages = st.number_input("í¬ë¡¤ë§í•  ë‰´ìŠ¤ í˜ì´ì§€ ìˆ˜ ì…ë ¥ (10ê°œ ë‹¨ìœ„)", min_value=1, max_value=10, step=1)

    if st.button("ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§í•˜ê¸°"):
        df_today = crawl_news(QUERY, pages)
        df_all = save_news(df_today)
        st.success(f"{len(df_today)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ! ì „ì²´ {len(df_all)}ê±´ ì €ì¥ë¨.")
    elif os.path.exists(FILE_PATH):
        df_all = pd.read_csv(FILE_PATH)
    else:
        st.warning("ì €ì¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        df_all = pd.DataFrame()

    if not df_all.empty:
        st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_all[['date', 'title', 'press', 'summary']])
        show_news(df_all)
    else:
        st.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")