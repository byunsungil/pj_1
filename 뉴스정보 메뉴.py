import seaborn as sns
import requests
from bs4 import BeautifulSoup
from collections import Counter
import re
from datetime import datetime, timedelta
import matplotlib.font_manager as fm


# ë‰´ìŠ¤ ì •ë³´ ë©”ë‰´
elif menu == "ë‰´ìŠ¤ ì •ë³´":
    st.title("ğŸ“° ë²•ì¸ ê´€ë ¨ ë‰´ìŠ¤")
    st.title("ğŸ“Š ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„") 
    QUERY = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="ë²•ì¸ì°¨ ì œë„")
    FILE_PATH = f"news_data/{QUERY}_news.csv"
    os.makedirs("news_data", exist_ok=True)

    def parse_date(text):
        if 'ì¼ ì „' in text:
            return datetime.now() - timedelta(days=int(text.replace('ì¼ ì „', '').strip()))
        elif 'ì‹œê°„ ì „' in text:
            return datetime.now()
        elif '.' in text:
            try:
                return datetime.strptime(text.strip(), "%Y.%m.%d.")
            except:
                return None
        return None

    def crawl_news(query, pages=1):
        data = []
        for page in range(1, pages + 1):
            start = (page - 1) * 10 + 1
            url = f'https://search.naver.com/search.naver?where=news&query={query}&start={start}'
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
            articles = soup.select('div.news_wrap.api_ani_send')

            for article in articles:
                title_tag = article.select_one('a.news_tit')
                if not title_tag:
                    continue
                title = title_tag['title']
                link = title_tag['href']
                press_tag = article.select_one('a.info.press')
                press = press_tag.text.strip() if press_tag else 'Unknown'
                date_tag = article.select('span.info')[-1]
                raw_date = date_tag.text.strip() if date_tag else ''
                parsed = parse_date(raw_date)
                date = parsed.strftime('%Y-%m-%d') if parsed else datetime.today().strftime('%Y-%m-%d')
                summary_tag = article.select_one('div.dsc_wrap')
                summary = summary_tag.text.strip() if summary_tag else ''
                data.append({'title': title, 'press': press, 'date': date, 'summary': summary, 'url': link})
        return pd.DataFrame(data)

    def save_news(df_new):
        if os.path.exists(FILE_PATH):
            df_old = pd.read_csv(FILE_PATH)
            df_all = pd.concat([df_old, df_new]).drop_duplicates(subset=['url'])
        else:
            df_all = df_new
        df_all.to_csv(FILE_PATH, index=False, encoding='utf-8-sig')
        return df_all

    def keyword_visualization(df):
        font_path = './fonts/NanumGothicCoding.ttf'
        font_name = fm.FontProperties(fname=font_path).get_name() if os.path.exists(font_path) else 'Malgun Gothic'
        plt.rcParams['font.family'] = font_name
        plt.rcParams['axes.unicode_minus'] = False

        all_words = []
        for summary in df['summary'].dropna():
            words = re.findall(r"[ê°€-í£]{2,}", summary)
            all_words.extend(words)

        counter = Counter(all_words)
        common_keywords = counter.most_common(20)
        if not common_keywords:
            st.warning("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        words, counts = zip(*common_keywords)
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(x=list(counts), y=list(words), ax=ax)
        ax.set_title('ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„')
        st.pyplot(fig)

    def show_news(df):
        st.subheader("ğŸ“° ë‰´ìŠ¤ ì œëª© ë° ìš”ì•½ ë³´ê¸°")
        def truncate(text, limit=100):
            return text if len(text) <= limit else text[:limit] + "..."

        if st.checkbox("ë‰´ìŠ¤ ì œëª© + ë§í¬ + ìš”ì•½ ë³´ê¸°", value=True):
            for i, row in df.iterrows():
                title = row['title']
                link = row['url']
                summary = row['summary']
                st.markdown(f"### ğŸ”— [{title}]({link})")
                st.write(f"ğŸ“ ìš”ì•½: {truncate(summary, 100)}")
                st.markdown("---")

    pages = st.number_input("í¬ë¡¤ë§í•  ë‰´ìŠ¤ í˜ì´ì§€ ìˆ˜ ì…ë ¥ (10ê°œ ë‹¨ìœ„)", min_value=1, max_value=10, step=1)

    if st.button("ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§í•˜ê¸°"):
        df_today = crawl_news(QUERY, pages)
        df_all = save_news(df_today)
        st.success(f"{len(df_today)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ! ì „ì²´ {len(df_all)}ê±´ ì €ì¥ë¨.")
    elif os.path.exists(FILE_PATH):
        df_all = pd.read_csv(FILE_PATH)
    else:
        st.warning("ì €ì¥ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        df_all = pd.DataFrame()

    if not df_all.empty:
        st.subheader("ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df_all[['date', 'title', 'press', 'summary']])

        st.subheader("í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼")
        keyword_visualization(df_all)

        show_news(df_all)
    else:
        st.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")